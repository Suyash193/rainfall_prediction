import matplotlib.pyplot as plt
import tensorflow as tf
import numpy as np
import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split

#Reading the dataset
def read_dataset():
    df = pd.read_csv("/home/rajeev/minor_project/dataset.csv")
    # print(len(df.columns))
    X = df[df.columns[0:5]].values
    Y = df[df.columns[5]]
    return (X, Y)

# Read the read_dataset
X, Y = read_dataset()

# Shuffle the dataset to mix up the rows.
X, Y = shuffle(X, Y, random_state=1)

# Convert the dataset into train and test part
train_x, test_x, train_y, test_y = train_test_split(X, Y,test_size=0.20, random_state=42)

# Inpect the shape of the training and testing.
print(train_x.shape)
print(train_y.shape)
print(test_x.shape)

print(train_x)
print(train_y)
# Define the important parameters and variable to work with the tensors
learning_rate = 0.3
training_epochs = 100
#cost_history = np.empty(shape=[1], dtype=float)
n_dim = X.shape[1]
print("n_dim", n_dim)

x = tf.placeholder(tf.float64, [None, n_dim])
W = tf.Variable(tf.zeros([n_dim]))
b = tf.Variable([0.1],tf.float64)
y = tf.placeholder(tf.float64)
linear_model=tf.add(tf.matmul(x, W), b)

init=tf.global_variables_initializer()

sess=tf.Session()

squared_deltas=tf.square(linear_model-y)
loss=tf.reduce_sum(squared_deltas)
#print(sess.run(loss,{x:[1,2,3,4],y:[0,-1,-2,-3]}))

optimizer=tf.train.GradientDescentOptimizer(learning_rate)

train=optimizer.minimize(loss)

sess.run(init)

for i in range(training_epochs):
    sess.run(train,feed_dict={x: train_x, y: train_y})
print(sess.run([W,b]))
sess.close()
